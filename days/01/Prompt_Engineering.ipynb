{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe058aa2"
      },
      "source": [
        "# Prompt Engineering Guide\n",
        "Prompt engineering is a relatively new discipline for developing and optimizing prompts to efficiently apply and build with large language models (LLMs) for a wide variety of applications and use cases.\n",
        "\n",
        "**Prompt engineering skills help to better understand the capabilities and limitations of LLMs. Researchers use prompt engineering to improve safety and the capacity of LLMs on a wide range of common and complex tasks such as question answering and arithmetic reasoning. Developers use prompt engineering to design robust and effective prompting techniques that interface with LLMs and other tools.**\n",
        "\n",
        "This comprehensive guide covers the theory and practical aspects of prompt engineering and how to leverage the best prompting techniques to interact and build with LLMs.\n",
        "\n",
        "This guide will cover:\n",
        "\n",
        "*   Basic prompt structure\n",
        "*   Techniques for improving prompt effectiveness\n",
        "*   Examples of prompt engineering for different tasks\n",
        "*   Tips for debugging and refining prompts\n",
        "\n",
        "## Basic Prompt Structure\n",
        "\n",
        "A basic prompt often includes:\n",
        "\n",
        "1.  **Instruction:** What you want the model to do.\n",
        "2.  **Context (Optional):** Any background information the model needs.\n",
        "3.  **Input Data (Optional):** The specific data the model should process.\n",
        "4.  **Output Indicator (Optional):** How you want the output to be formatted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.77.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: exceptiongroup in c:\\users\\dell\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.0.4)\n",
            "Requirement already satisfied: certifi in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q python-dotenv\n",
        "%pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking for .env at: C:\\Users\\DELL\\Documents\\ai crafters\\10dayschallenge_AIC\\10-day-ai-build-sprint\\days\\.env\n",
            "sk-or...\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Go up one directory (from /days/01 → /days) and load .env\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "env_path = Path(\"C:/Users/DELL/Documents/ai crafters/10dayschallenge_AIC/10-day-ai-build-sprint/days/.env\").resolve()\n",
        "print(\"Looking for .env at:\", env_path)\n",
        "\n",
        "load_dotenv(dotenv_path=env_path)\n",
        "\n",
        "\n",
        "# Now you can use the key\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "print(api_key[:5] + \"...\" if api_key else \"API key not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bcedb8c",
        "outputId": "6621ca01-8848-4213-dfbf-c4f4c5f7aa04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to call model: openai/gpt-oss-20b:free\n",
            "Response from LLM:\n",
            "In a quiet corner of Maplewood’s bustling town library, there was a place that no one ever noticed until a particular dog began to visit it. The library had a small, sun‑lit reading nook by the window, a tuft of carpet, and a single armchair that seemed to beckon anyone who needed a quiet pause. Milo, a sprightly terrier with a coat the color of autumn leaves, would trot through the library every afternoon, tail wagging like a metronome set to a steady beat.\n",
            "\n",
            "Milo was not your typical book‑lover. He didn’t howl at the rustle of pages, nor did he sniff the dust off old encyclopedias. Instead, Milo’s eyes would light up when a new volume was placed on the shelf. He would circle it, sniff the spine, and then, with a precision that made the librarians smile, he’d nudge the book with his nose until it slipped open. His tiny paws, though not exactly suited for handling paper, would press the pages together, and he would stare at the words as if they were a language he was fluent in.\n",
            "\n",
            "The first librarian to notice Milo was Mrs. Patel, the librarian with silver hair and a perpetual cup of tea. One rainy afternoon, the rain drummed like applause against the library windows. Milo trotted in, his paws silent on the hardwood. He made his way to the corner, nudged a book titled *The Adventures of Sherlock Hound*, and settled into the armchair with a satisfied sigh. Mrs. Patel watched him for a moment and then, with a chuckle, let her tea go cold.\n",
            "\n",
            "“Seems like you’ve found a new reader,” she said to herself, and to Milo, she added, “Maybe you’re the one who needs the book, after all.”\n",
            "\n",
            "Word of Milo’s reading habit spread. Children brought their books to read aloud to him, hoping he might understand. Some older patrons began leaving notes on the books he visited, with simple, “Thank you for listening,” scribbled in a neat hand. Milo, in return, would pat the notes with his paw, as if acknowledging the gratitude in his own way.\n",
            "\n",
            "One day, a young girl named Lila approached Milo with a bright, oversized book—*The Secret Garden*—in her arms. She set it down and opened it at a random page. Milo’s ears perked up, and he settled on the floor beside the chair. Lila began reading aloud. Her voice wavered at the beginning but grew stronger as she moved through the story. Milo listened with an intensity that made the other patrons smile. When Lila paused, Milo lifted his paw, nudging the next page. She laughed, then continued.\n",
            "\n",
            "Mrs. Patel noticed the connection between Milo and Lila. She proposed an idea: “Why not set up a ‘Reading with Milo’ program?” She imagined after-school sessions where kids could bring books, sit with Milo, and read aloud. The idea took root, and soon, the library had an official schedule for Milo’s reading sessions.\n",
            "\n",
            "The program was a hit. Children learned to read in a relaxed environment; even the shyest of them found courage in the presence of Milo. Lila, who had once found reading intimidating, became a regular participant. She would bring her book, sit beside Milo, and read aloud until the story’s end. Milo would listen, his tail thumping gently, giving the illusion of approval. Mrs. Patel often watched with a smile, feeling the quiet joy that a simple animal could bring into the community.\n",
            "\n",
            "As autumn turned to winter, the library’s reading nook became a place where the line between humans and animals blurred. Milo’s love for books was not just a quirk; it was a bridge. He reminded everyone that stories didn’t need to be read by humans alone. They could be shared, listened to, and even appreciated by a dog who loved to read.\n",
            "\n",
            "When Milo finally grew old, he spent his last days curled up beside the window, the same armchair, a pile of books by his side. The library held a small ceremony in his honor, with the children who’d once stared in wonder now speaking of the dog who had taught them the beauty of a shared story. Milo’s story became a part of the library’s history—a living testament that a dog’s love for reading could indeed touch hearts, one paw at a time.\n",
            "\n",
            "Full chat_completion object:\n",
            "ChatCompletion(id='gen-1756306623-qBDpiZlihpyvWmtakb3A', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='In a quiet corner of Maplewood’s bustling town library, there was a place that no one ever noticed until a particular dog began to visit it. The library had a small, sun‑lit reading nook by the window, a tuft of carpet, and a single armchair that seemed to beckon anyone who needed a quiet pause. Milo, a sprightly terrier with a coat the color of autumn leaves, would trot through the library every afternoon, tail wagging like a metronome set to a steady beat.\\n\\nMilo was not your typical book‑lover. He didn’t howl at the rustle of pages, nor did he sniff the dust off old encyclopedias. Instead, Milo’s eyes would light up when a new volume was placed on the shelf. He would circle it, sniff the spine, and then, with a precision that made the librarians smile, he’d nudge the book with his nose until it slipped open. His tiny paws, though not exactly suited for handling paper, would press the pages together, and he would stare at the words as if they were a language he was fluent in.\\n\\nThe first librarian to notice Milo was Mrs. Patel, the librarian with silver hair and a perpetual cup of tea. One rainy afternoon, the rain drummed like applause against the library windows. Milo trotted in, his paws silent on the hardwood. He made his way to the corner, nudged a book titled *The Adventures of Sherlock Hound*, and settled into the armchair with a satisfied sigh. Mrs. Patel watched him for a moment and then, with a chuckle, let her tea go cold.\\n\\n“Seems like you’ve found a new reader,” she said to herself, and to Milo, she added, “Maybe you’re the one who needs the book, after all.”\\n\\nWord of Milo’s reading habit spread. Children brought their books to read aloud to him, hoping he might understand. Some older patrons began leaving notes on the books he visited, with simple, “Thank you for listening,” scribbled in a neat hand. Milo, in return, would pat the notes with his paw, as if acknowledging the gratitude in his own way.\\n\\nOne day, a young girl named Lila approached Milo with a bright, oversized book—*The Secret Garden*—in her arms. She set it down and opened it at a random page. Milo’s ears perked up, and he settled on the floor beside the chair. Lila began reading aloud. Her voice wavered at the beginning but grew stronger as she moved through the story. Milo listened with an intensity that made the other patrons smile. When Lila paused, Milo lifted his paw, nudging the next page. She laughed, then continued.\\n\\nMrs. Patel noticed the connection between Milo and Lila. She proposed an idea: “Why not set up a ‘Reading with Milo’ program?” She imagined after-school sessions where kids could bring books, sit with Milo, and read aloud. The idea took root, and soon, the library had an official schedule for Milo’s reading sessions.\\n\\nThe program was a hit. Children learned to read in a relaxed environment; even the shyest of them found courage in the presence of Milo. Lila, who had once found reading intimidating, became a regular participant. She would bring her book, sit beside Milo, and read aloud until the story’s end. Milo would listen, his tail thumping gently, giving the illusion of approval. Mrs. Patel often watched with a smile, feeling the quiet joy that a simple animal could bring into the community.\\n\\nAs autumn turned to winter, the library’s reading nook became a place where the line between humans and animals blurred. Milo’s love for books was not just a quirk; it was a bridge. He reminded everyone that stories didn’t need to be read by humans alone. They could be shared, listened to, and even appreciated by a dog who loved to read.\\n\\nWhen Milo finally grew old, he spent his last days curled up beside the window, the same armchair, a pile of books by his side. The library held a small ceremony in his honor, with the children who’d once stared in wonder now speaking of the dog who had taught them the beauty of a shared story. Milo’s story became a part of the library’s history—a living testament that a dog’s love for reading could indeed touch hearts, one paw at a time.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning=\"We need a short story about a dog who loves to read. Should be creative, maybe anthropomorphic. Write in engaging narrative. Let's craft about a dog named Milo or something. The dog loves books, maybe the owner reads to him. He might use paw to open pages, etc. Could have twist that the dog reads to help the owner. We'll keep it short, maybe 500-600 words. Let's write in third person. Use simple language but vivid. We'll include some humor. The dog might be a librarian dog. We'll incorporate the love of reading, the dog's curiosity, the owner's reaction, and maybe a lesson about learning. We'll keep it short but descriptive. Let's craft.\", reasoning_details=[{'type': 'reasoning.text', 'text': \"We need a short story about a dog who loves to read. Should be creative, maybe anthropomorphic. Write in engaging narrative. Let's craft about a dog named Milo or something. The dog loves books, maybe the owner reads to him. He might use paw to open pages, etc. Could have twist that the dog reads to help the owner. We'll keep it short, maybe 500-600 words. Let's write in third person. Use simple language but vivid. We'll include some humor. The dog might be a librarian dog. We'll incorporate the love of reading, the dog's curiosity, the owner's reaction, and maybe a lesson about learning. We'll keep it short but descriptive. Let's craft.\", 'format': 'unknown', 'index': 0}]), native_finish_reason='stop')], created=1756306624, model='openai/gpt-oss-20b:free', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1047, prompt_tokens=83, total_tokens=1130, completion_tokens_details=None, prompt_tokens_details=None), provider='AtlasCloud')\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "# It's recommended to store your API key securely, for example, in Colab Secrets\n",
        "#from google.colab import userdata\n",
        "#gpt_key= userdata.get('gpt')\n",
        "\n",
        "\n",
        "\n",
        "dotenv_path = Path(r\"C:\\days\\.env\")  # point to the other folder\n",
        "load_dotenv(dotenv_path=dotenv_path, override=True)\n",
        "\n",
        "gpt_key= os.getenv('OPENAI_API_KEY ')\n",
        "client = OpenAI(\n",
        "        base_url=\"https://openrouter.ai/api/v1\",\n",
        "        api_key=gpt_key,\n",
        ")\n",
        "\n",
        "\n",
        "# Example prompt\n",
        "prompt_text = \"Write a short story about a dog who loves to read.\"\n",
        "\n",
        "# Example API call (using a model available on OpenRouter)\n",
        "# You can find available models and their names on the OpenRouter website\n",
        "model_name = \"openai/gpt-oss-20b:free\" # Example model, choose one from OpenRouter\n",
        "print(f\"Attempting to call model: {model_name}\")\n",
        "\n",
        "try:\n",
        "  chat_completion = client.chat.completions.create(\n",
        "  model=model_name,\n",
        "  messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
        "  temperature=0.7,\n",
        "  max_tokens=1050,\n",
        "        )\n",
        "  print(\"Response from LLM:\")\n",
        "  print(chat_completion.choices[0].message.content)\n",
        "  # Optionally, print the full object for debugging:\n",
        "  print(\"\\nFull chat_completion object:\")\n",
        "  print(chat_completion)\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred during the API call: {e}\")\n",
        "  print(f\"Please ensure your API key is correct and the model '{model_name}' is valid and available on OpenRouter.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G7EVmybsLSE",
        "outputId": "013bb923-1589-4cc8-be72-471e2c954b62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The question “What is the meaning of life?” has fascinated philosophers, scientists, artists, and ordinary people for millennia. Because it touches on the deepest parts of our existence—our purpose, our values, the significance of our experiences—there is no single answer that satisfies everyone. Instead, most thinkers agree that the meaning of life is something we create, discover, or interpret rather than uncover.\n",
            "\n",
            "---\n",
            "\n",
            "## 1. A Personal Canvas: Constructing Your Own Meaning\n",
            "\n",
            "### *Existentialist View*\n",
            "Existentialists like Jean Paul Sartre and Albert Camus argue that life is inherently meaningless, but that freedom gives us the responsibility to give it meaning. In this view, your purpose is self‑authored: the projects you choose, the relationships you nurture, the passions you pursue—all of these become the “meaning” of your life.\n",
            "\n",
            "### *Humanistic Psychology*\n",
            "Carl Rogers and Abraham Maslow suggest that meaning arises from growth, self‑actualization, and authenticity. When you align your actions with your deepest values and potentials, you experience a sense of purpose.\n",
            "\n",
            "### *Practical Takeaway*\n",
            "- **Ask**: What brings you joy, fulfillment, or a sense of contribution?\n",
            "- **Experiment**: Try new activities, volunteer, learn, or create. Notice what feels “right.”\n",
            "- **Reflect**: Keep a journal or discuss with trusted friends. Over time you’ll see patterns that point to your own meaning.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. A Shared Human Story: Collective Perspectives\n",
            "\n",
            "### *Religious and Spiritual Traditions*\n",
            "Most world religions propose that life’s meaning comes from a relationship with the divine or a cosmic order. For example:\n",
            "- **Christianity**: Love God and others; live according to divine commandments.\n",
            "- **Buddhism**: Seek enlightenment and reduce suffering through mindfulness and compassion.\n",
            "- **Islam**: Serve Allah, uphold justice, and live a virtuous life.\n",
            "\n",
            "### *Secular Ethics*\n",
            "Philosophers like John Rawls or Peter Singer argue that moral duties—fairness, compassion, stewardship—give life purpose. The meaning is found in acting for the common good and respecting others’ autonomy.\n",
            "\n",
            "### *Scientific Lens*\n",
            "From a biological standpoint, the meaning could be as simple as survival and reproduction. Yet many scientists see meaning in the quest for knowledge, curiosity, and the understanding of the universe.\n",
            "\n",
            "### *Practical Takeaway*\n",
            "- **Explore**: Read texts, attend services, or study philosophies that resonate with you.\n",
            "- **Integrate**: Combine insights from different traditions if they add value.\n",
            "- **Live**: Apply principles that align with your values, whether they’re religious, ethical, or scientific.\n",
            "\n",
            "---\n",
            "\n",
            "## 3. The “Universal” Threads Often Found in Meaningful Lives\n",
            "\n",
            "| Thread | Why It Matters | How It Shows Up |\n",
            "|--------|----------------|-----------------|\n",
            "| **Connection** | Humans are social beings; relationships give context to our actions. | Family, friendships, community service. |\n",
            "| **Growth** | Learning and development keep life dynamic. | Education, skill‑building, personal reflection. |\n",
            "| **Contribution** | Making a difference fosters a sense of purpose. | Volunteering, creative work, mentoring. |\n",
            "| **Passion** | Pursuing what excites you fuels energy and resilience. | Hobbies, career choices, causes you care about. |\n",
            "| **Mindfulness** | Staying present reduces anxiety and enhances appreciation. | Meditation, journaling, slow living. |\n",
            "\n",
            "---\n",
            "\n",
            "## 4. A Simple Experiment: “The Meaning Map”\n",
            "\n",
            "1. **List 3 activities that make you feel alive.**  \n",
            "2. **Ask each: “Why does this matter to me?”**  \n",
            "3. **Identify common values that emerge.**  \n",
            "4. **Sketch a rough “meaning map” linking activities → values → impact.**\n",
            "\n",
            "This visual can help you see connections you might miss in conversation.\n",
            "\n",
            "---\n",
            "\n",
            "## 5. A Final Thought\n",
            "\n",
            "Many people find that the search itself becomes part of life’s meaning. When we ask, we engage our curiosity, we confront uncertainty, and we become active participants in our own story. Whether you lean toward a grand cosmic purpose or a simple personal fulfillment, the act of seeking—and living with intention—makes life profoundly meaningful.\n",
            "\n",
            "---\n",
            "\n",
            "### Takeaway\n",
            "\n",
            "- **Meaning is personal yet universal in its core threads.**  \n",
            "- **It can be discovered, created, or interpreted.**  \n",
            "- **Reflect, experiment, and act in alignment with your values.**  \n",
            "\n",
            "If you’d like to explore a specific tradition, philosophy, or activity\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=gpt_key,\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  extra_body={},\n",
        "  model=\"openai/gpt-oss-20b:free\",\n",
        "  temperature=0.7,\n",
        "  max_tokens=1000,\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"What is the meaning of life?\"\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFp1zhgyHbwR"
      },
      "source": [
        "## LLM Settings\n",
        "* **Temperature** → controls randomness of next-token choice.\n",
        "\n",
        "  * Lower (0–0.3): more deterministic, concise (good for fact Q&A).\n",
        "\n",
        "  * Higher (0.7–1.0+): more varied/creative (good for poems/brainstorm).\n",
        "\n",
        "* **Top-p** (nucleus sampling) → limits choices to the smallest set whose probabilities sum to p.\n",
        "\n",
        "  * Lower (0.1–0.3): very focused, conservative.\n",
        "\n",
        "  * Higher (0.9–1.0): considers more (rarer) words → more diversity.\n",
        "\n",
        "      * Tip: tune either temperature or top-p, not both.\n",
        "\n",
        "* **Max length** (max tokens) → hard cap on output size.\n",
        "\n",
        "  * Prevents run-on/irrelevant answers and manages cost.\n",
        "\n",
        "  * Stop sequences → strings that make the model stop generating.\n",
        "\n",
        "  * Use to enforce structure/length (e.g., stop at \"11\" to cap a numbered list at 10).\n",
        "\n",
        "* **Frequency penalty** → reduces reuse proportional to how often a token already appeared.\n",
        "\n",
        "  * Higher value = fewer repeated words.\n",
        "\n",
        "  * Presence penalty → discourages any repeated token equally (once it’s appeared).\n",
        "\n",
        "  * Higher value = less phrase repetition; boosts topical variety.\n",
        "\n",
        "  * Use higher for exploration/creativity; lower to keep the model tightly on topic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "319fba6b"
      },
      "source": [
        "## Prompt Examples\n",
        "Here are examples of Zero-shot, One-shot, and Few-shot prompting techniques:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Iqh59uCEFPs"
      },
      "source": [
        "### Zero-shot Prompting\n",
        "\n",
        "Zero-shot prompting is when you give the model a task without providing any examples of how to do it. The model relies solely on its pre-training to understand and complete the task.\n",
        "\n",
        "**Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23e5bebd",
        "outputId": "a28cea84-98a7-462d-fc3d-a32dd8778af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zero-shot Prompt:\n",
            "Classify the following text as positive, negative, or neutral: 'I love this new movie!'\n"
          ]
        }
      ],
      "source": [
        "# Zero-shot Prompt Example\n",
        "zero_shot_prompt = \"Classify the following text as positive, negative, or neutral: 'I love this new movie!'\"\n",
        "print(f\"Zero-shot Prompt:\\n{zero_shot_prompt}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLCNuCD0Dk1L"
      },
      "source": [
        "### One-shot Prompting\n",
        "One-shot prompting is when you provide the model with one example of the task you want it to perform, along with the desired output for that example. This helps the model understand the format and style you're looking for in its response to your actual query.\n",
        "\n",
        "**Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6136412",
        "outputId": "6de8cc1a-9a79-45a6-877d-cfe21daa9df3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-shot Prompt:\n",
            "Given the following example, classify the next text.\n",
            "\n",
            "Example:\n",
            "Text: 'This is a terrible product.'\n",
            "Sentiment: Negative\n",
            "\n",
            "Classify the following text:\n",
            "Text: 'The weather is nice today.'\n",
            "Sentiment:\n"
          ]
        }
      ],
      "source": [
        "# One-shot Prompt Example\n",
        "one_shot_prompt = \"\"\"Given the following example, classify the next text.\n",
        "\n",
        "Example:\n",
        "Text: 'This is a terrible product.'\n",
        "Sentiment: Negative\n",
        "\n",
        "Classify the following text:\n",
        "Text: 'The weather is nice today.'\n",
        "Sentiment:\"\"\"\n",
        "print(f\"One-shot Prompt:\\n{one_shot_prompt}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycp2jX3yDvzm"
      },
      "source": [
        "### Few-shot prompting\n",
        "Few-shot prompting is similar to one-shot prompting, but instead of just one example, you provide the model with a few examples (typically between 2 and 5) of the task and their corresponding outputs. This gives the model more context and helps it to better grasp the pattern or logic required to complete the task accurately.\n",
        "\n",
        "**Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b58601f",
        "outputId": "0a28cac2-76e2-458d-d9f7-36fc98b08369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Few-shot Prompt:\n",
            "Given the following examples, classify the next text.\n",
            "\n",
            "Example 1:\n",
            "Text: 'I had a wonderful time.'\n",
            "Sentiment: Positive\n",
            "\n",
            "Example 2:\n",
            "Text: 'The service was slow.'\n",
            "Sentiment: Negative\n",
            "\n",
            "Example 3:\n",
            "Text: 'It was an average experience.'\n",
            "Sentiment: Neutral\n",
            "\n",
            "Classify the following text:\n",
            "Text: 'I would recommend this restaurant.'\n",
            "Sentiment:\n"
          ]
        }
      ],
      "source": [
        "# Few-shot Prompt Example\n",
        "few_shot_prompt = \"\"\"Given the following examples, classify the next text.\n",
        "\n",
        "Example 1:\n",
        "Text: 'I had a wonderful time.'\n",
        "Sentiment: Positive\n",
        "\n",
        "Example 2:\n",
        "Text: 'The service was slow.'\n",
        "Sentiment: Negative\n",
        "\n",
        "Example 3:\n",
        "Text: 'It was an average experience.'\n",
        "Sentiment: Neutral\n",
        "\n",
        "Classify the following text:\n",
        "Text: 'I would recommend this restaurant.'\n",
        "Sentiment:\"\"\"\n",
        "print(f\"Few-shot Prompt:\\n{few_shot_prompt}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8Xhv8cIEh_N",
        "outputId": "0e8c9038-e427-4ae5-ae34-57e5e2564e3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sending Zero-shot Prompt ---\n",
            "Prompt:\n",
            "Classify the following text as positive, negative, or neutral: 'I love this new movie!'\n",
            "Attempting to call model: openai/gpt-oss-20b:free\n",
            "Response from LLM (Zero-shot):\n",
            "positive\n",
            "\n",
            "--- Sending One-shot Prompt ---\n",
            "Prompt:\n",
            "Given the following example, classify the next text.\n",
            "\n",
            "Example:\n",
            "Text: 'This is a terrible product.'\n",
            "Sentiment: Negative\n",
            "\n",
            "Classify the following text:\n",
            "Text: 'The weather is nice today.'\n",
            "Sentiment:\n",
            "Attempting to call model: openai/gpt-oss-20b:free\n",
            "Response from LLM (One-shot):\n",
            "Sentiment: Positive\n",
            "\n",
            "--- Sending Few-shot Prompt ---\n",
            "Prompt:\n",
            "Given the following examples, classify the next text.\n",
            "\n",
            "Example 1:\n",
            "Text: 'I had a wonderful time.'\n",
            "Sentiment: Positive\n",
            "\n",
            "Example 2:\n",
            "Text: 'The service was slow.'\n",
            "Sentiment: Negative\n",
            "\n",
            "Example 3:\n",
            "Text: 'It was an average experience.'\n",
            "Sentiment: Neutral\n",
            "\n",
            "Classify the following text:\n",
            "Text: 'I would recommend this restaurant.'\n",
            "Sentiment:\n",
            "Attempting to call model: openai/gpt-oss-20b:free\n",
            "Response from LLM (Few-shot):\n",
            "Sentiment: Positive\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'client' is already defined and configured from a previous cell\n",
        "# and 'zero_shot_prompt', 'one_shot_prompt', and 'few_shot_prompt' are defined\n",
        "\n",
        "prompts = {\n",
        "    \"Zero-shot\": zero_shot_prompt,\n",
        "    \"One-shot\": one_shot_prompt,\n",
        "    \"Few-shot\": few_shot_prompt\n",
        "}\n",
        "\n",
        "for prompt_type, prompt_text in prompts.items():\n",
        "  print(f\"\\n--- Sending {prompt_type} Prompt ---\")\n",
        "  print(f\"Prompt:\\n{prompt_text}\")\n",
        "  print(f\"Attempting to call model: {model_name}\")\n",
        "\n",
        "  try:\n",
        "    chat_completion = client.chat.completions.create(\n",
        "    model=\"openai/gpt-oss-20b:free\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
        "    temperature=0.7,\n",
        "    max_tokens=1050,\n",
        "          )\n",
        "    print(f\"Response from LLM ({prompt_type}):\")\n",
        "    print(chat_completion.choices[0].message.content)\n",
        "    # Optionally, print the full object for debugging:\n",
        "    # print(f\"\\nFull chat_completion object ({prompt_type}):\")\n",
        "    # print(chat_completion)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during the API call for {prompt_type} prompt: {e}\")\n",
        "    print(f\"Please ensure your API key is correct and the model '{model_name}' is valid and available on OpenRouter.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b66a625"
      },
      "source": [
        "## Chain-of-Thought Prompting\n",
        "\n",
        "Chain-of-Thought (CoT) prompting is a technique that encourages the language model to explain its reasoning process step-by-step before arriving at the final answer. This can lead to more accurate and reliable results, especially for complex tasks, as it allows the model to break down the problem and work through it logically.\n",
        "\n",
        "**How it works:**\n",
        "\n",
        "By adding phrases like \"Let's think step by step\" or explicitly asking for intermediate steps, you guide the model to generate a series of thoughts or reasoning steps that lead to the solution.\n",
        "\n",
        "**Benefits of CoT:**\n",
        "\n",
        "* **Improved accuracy:** Breaking down complex problems into smaller steps reduces the chance of errors.\n",
        "* **Increased transparency:** You can see how the model arrived at its answer, making it easier to debug or understand its limitations.\n",
        "* **Better performance on complex tasks:** CoT has shown significant improvements on tasks requiring multi-step reasoning, like arithmetic or symbolic manipulation.\n",
        "\n",
        "**Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "af5d430e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chain-of-Thought Prompt:\n",
            "The original price of a shirt was $20. It was discounted by 25%, and then an additional 10% discount was applied to the sale price. What is the final price of the shirt?\n",
            "\n",
            "Let's think step by step.\n"
          ]
        }
      ],
      "source": [
        "# Chain-of-Thought Prompt Example\n",
        "cot_prompt = \"\"\"The original price of a shirt was $20. It was discounted by 25%, and then an additional 10% discount was applied to the sale price. What is the final price of the shirt?\n",
        "\n",
        "Let's think step by step.\"\"\"\n",
        "\n",
        "print(f\"Chain-of-Thought Prompt:\\n{cot_prompt}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to call model: openai/gpt-oss-20b:free\n",
            "Response (Chain-of-Thought):\n",
            "\n",
            "**Step 1 – First discount (25 %)**\n",
            "\n",
            "\\[\n",
            "\\text{Price after first discount} = 20 \\times (1 - 0.25) = 20 \\times 0.75 = \\$15.00\n",
            "\\]\n",
            "\n",
            "**Step 2 – Second discount (10 %)**\n",
            "\n",
            "\\[\n",
            "\\text{Final price} = 15 \\times (1 - 0.10) = 15 \\times 0.90 = \\$13.50\n",
            "\\]\n",
            "\n",
            "\\[\n",
            "\\boxed{\\$13.50}\n",
            "\\]\n"
          ]
        }
      ],
      "source": [
        "# Send the Chain-of-Thought prompt to the LLM and print the response\n",
        "try:\n",
        "  model_name = \"openai/gpt-oss-20b:free\"\n",
        "  print(f\"Attempting to call model: {model_name}\")\n",
        "  chat_completion = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "    temperature=0.2,\n",
        "    max_tokens=300\n",
        "  )\n",
        "  print(\"Response (Chain-of-Thought):\\n\")\n",
        "  print(chat_completion.choices[0].message.content)\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred during the API call: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## System / Role Prompting\n",
        "\n",
        "You can steer behavior with explicit roles:\n",
        "\n",
        "- **system**: high-level instructions and persona\n",
        "- **user**: task request\n",
        "- **assistant**: optional exemplars or tools output\n",
        "\n",
        "This helps keep outputs consistent, especially for style and safety.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to call model: openai/gpt-oss-20b:free\n",
            "Response (System/Role Prompting):\n",
            "\n",
            "- Embeddings: vector representations capturing semantic meaning of data.  \n",
            "- Use‑case: search engines match queries to documents via embeddings.\n"
          ]
        }
      ],
      "source": [
        "# System / Role Prompting demo\n",
        "system_msg = (\n",
        "  \"You are a concise technical writer. Answer in bullet points, each under 12 words.\"\n",
        ")\n",
        "user_msg = \"Explain what embeddings are and one practical use-case.\"\n",
        "\n",
        "try:\n",
        "  model_name = \"openai/gpt-oss-20b:free\"\n",
        "  print(f\"Attempting to call model: {model_name}\")\n",
        "  completion = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    temperature=0.4,\n",
        "    max_tokens=200,\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": system_msg},\n",
        "      {\"role\": \"user\", \"content\": user_msg}\n",
        "    ]\n",
        "  )\n",
        "  print(\"Response (System/Role Prompting):\\n\")\n",
        "  print(completion.choices[0].message.content)\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stop Sequences\n",
        "Use stop strings to end generation at desired boundaries (e.g., JSON blocks, section breaks).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response (Stop sequences; should stop before item 6):\n",
            "\n",
            "**10 Safety Tips for Prompt Engineering**\n",
            "\n",
            "1. **Start with a Clear Objective**  \n",
            "   Define the exact purpose of the prompt before drafting it—this reduces ambiguity and limits unintended outputs.\n",
            "\n",
            "2. **Use Explicit Constraints**  \n",
            "   Include specific rules or boundaries (e.g., “no political content,” “avoid profanity”) to guide the model’s responses.\n",
            "\n",
            "3. **Iteratively Refine Prompts**  \n",
            "   Test and tweak prompts in small steps, monitoring outputs for safety violations before scaling.\n",
            "\n",
            "4. **Implement Guardrails in Code**  \n",
            "   Wrap the model call in automated checks that flag or block content violating your safety policies.\n",
            "\n",
            "5. **Limit Sensitive Data Exposure**  \n",
            "   Avoid embedding personal identifiers or confidential information in prompts; use anonymized placeholders instead.\n",
            "\n",
            "6. **Employ Contextual Cues Wisely**  \n",
            "   Provide enough background for the model to understand the task, but avoid overloading it with unrelated context that could trigger unsafe associations.\n",
            "\n",
            "7. **Use Prompt Templates**  \n",
            "   Reuse vetted templates that have already passed safety reviews, reducing the risk of accidental misuse.\n",
            "\n",
            "8. **Monitor for Hallucinations**  \n",
            "   Verify factual claims in model outputs, especially when prompts involve complex or technical subject matter.\n",
            "\n",
            "9. **Apply Post\n"
          ]
        }
      ],
      "source": [
        "# Stop sequence example: cap a numbered list at 5\n",
        "try:\n",
        "  model_name = \"openai/gpt-oss-20b:free\"\n",
        "  prompt_text = (\n",
        "    \"List 10 safety tips for prompt engineering as a numbered list.\"\n",
        "  )\n",
        "  completion = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    temperature=0.5,\n",
        "    max_tokens=300,\n",
        "    stop=[\"6.\", \"\\n6)\"],\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt_text}]\n",
        "  )\n",
        "  print(\"Response (Stop sequences; should stop before item 6):\\n\")\n",
        "  print(completion.choices[0].message.content)\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mini Exercise\n",
        "- Rewrite one of your prompts using role prompting and a stop sequence.\n",
        "- Run it with `temperature=0.3` and `max_tokens<=200`.\n",
        "- Paste the result below and note what changed."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
